{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"./../data/application_train.csv\",encoding=\"utf-8\",index_col=0)\n",
    "df_test=pd.read_csv(\"./../data/application_test.csv\",encoding=\"utf-8\",index_col=0)\n",
    "df = pd.concat([df_train,df_test])\n",
    "df_safe = pd.concat([df_train,df_test])\n",
    "df=df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparaison entre df et df sans les nan\n",
    "\n",
    "df_salvage_drop=df.dropna()\n",
    "' '.join(['ratio:' , str(df_salvage_drop.shape[0]) ,'/' , str(df.shape[0]), '=' , str(round(df_salvage_drop.shape[0]/df.shape[0]*100,2)), '%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste les valeurs par default de chaque clmn\n",
    "\n",
    "def one_line_try(serie):\n",
    "    try:\n",
    "        return float(serie.mean())\n",
    "    except:\n",
    "        return float(np.nan)\n",
    "    \n",
    "default_value_per_clmn = {clmn : one_line_try(df_salvage_drop[clmn]) for clmn in df_salvage_drop}\n",
    "\n",
    "default_value_per_clmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# applique ces valeur aux clmn\n",
    "\n",
    "for clmn in df:\n",
    "    df[clmn]= [A if str(A) != 'nan' else default_value_per_clmn[clmn] for A in df[clmn]]\n",
    "df_cute_drop = df.dropna()\n",
    "' '.join(['ratio:' , str(df_cute_drop.shape[0]) ,'/' , str(df.shape[0]), '=' ,str(round(df_cute_drop.shape[0]/df.shape[0]*100,2)), '%'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_cute_drop\n",
    "del df_salvage_drop\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes=[colonne for colonne in df]\n",
    "types_colonnes=list(map(lambda x : {x : list(set(df[x].map(lambda x : str(type(x)))))} , colonnes))\n",
    "colonnes_str=list(filter(lambda x : \"<class 'str'>\" in x[list(x)[0]], types_colonnes))\n",
    "\n",
    "def vectorisation(col):\n",
    "    voc=list(set(list(col)))\n",
    "    val={voc[i]:i for i in range(len(voc))}\n",
    "    return col.map(lambda x : val[x])\n",
    "\n",
    "\n",
    "\n",
    "for i in [list(i)[0] for i in colonnes_str]:\n",
    "    df[i]=vectorisation(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste les valeurs par default de chaque clmn\n",
    "\n",
    "def one_line_try(serie):\n",
    "    try:\n",
    "        return float(serie.mean())\n",
    "    except:\n",
    "        return float(np.nan)\n",
    "    \n",
    "default_value_per_clmn = {clmn : one_line_try(df[clmn]) for clmn in df}\n",
    "\n",
    "df = df_safe\n",
    "\n",
    "\n",
    "    \n",
    "for clmn in df:\n",
    "    df[clmn]= [A if str(A) != 'nan' else default_value_per_clmn[clmn] for A in df[clmn]]\n",
    "df_cute_drop = df.dropna()\n",
    "' '.join(['ratio:' , str(df_cute_drop.shape[0]) ,'/' , str(df.shape[0]), '=' ,str(round(df_cute_drop.shape[0]/df.shape[0]*100,2)), '%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_value_per_clmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_cute_drop\n",
    "df = df.dropna()\n",
    "\n",
    "colonnes=[colonne for colonne in df]\n",
    "types_colonnes=list(map(lambda x : {x : list(set(df[x].map(lambda x : str(type(x)))))} , colonnes))\n",
    "colonnes_str=list(filter(lambda x : \"<class 'str'>\" in x[list(x)[0]], types_colonnes))\n",
    "\n",
    "def vectorisation(col):\n",
    "    voc=list(set(list(col)))\n",
    "    val={voc[i]:i for i in range(len(voc))}\n",
    "    return col.map(lambda x : val[x])\n",
    "\n",
    "for i in [list(i)[0] for i in colonnes_str]:\n",
    "    df[i]=vectorisation(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_true = df[df['TARGET'] == 1]\n",
    "df_false = df[df['TARGET'] != 1]\n",
    "maxi_val = min([df_false.shape[0], df_true.shape[0]])\n",
    "maxsize = maxi_val*2\n",
    "print('whith parity: {} / {}'.format(maxsize,df.shape[0],round(maxsize/df.shape[0],2)))\n",
    "df = pd.concat([df_false.iloc[:maxi_val],df_true.iloc[:maxi_val]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OCCUPATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colonnes=[colonne for colonne in df]\n",
    "list(map(lambda x : {x : list(set(df[x].map(lambda x : str(type(x)))))} , colonnes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrice de correlation\n",
    "\n",
    "total_corr = df.corr()\n",
    "total_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste les meuilleurs correlations entre les clmns\n",
    "\n",
    "def get_coor(mat, corr = .75):\n",
    "    clmn_lst = mat.columns\n",
    "    exeption = [] \n",
    "    val = 0\n",
    "    for clmn in mat:\n",
    "        cmd = lambda idx, val: [print(\"{} -> {} : \".format(clmn, clmn_lst[idx]).ljust(80, ' ') + str(val)),  exeption.append(val)]\n",
    "        [cmd(idx, val) for idx, val in enumerate(mat[clmn]) if val > corr and val != 1 and val not in exeption]\n",
    "\n",
    "        \n",
    "\n",
    "get_coor(total_corr, .99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste les meuilleurs corelations par rapport a une clmn\n",
    "\n",
    "def get_clmn_corr(mat, clmn, corr = 0.1):\n",
    "    serie = mat[clmn]\n",
    "    clmn_lst = list(serie.keys())\n",
    "    cmd = lambda idx, val: print(\"{} -> {} : \".format(clmn, clmn_lst[idx]).ljust(80, ' ') + str(val))\n",
    "    [cmd(idx, val) for idx, val in enumerate(mat[clmn]) if abs(val) > corr and val != 1]\n",
    "    \n",
    "get_clmn_corr(total_corr, 'TARGET', 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(df_train['FONDKAPREMONT_MODE'].fillna(\"\").map(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(list(df.corr()['TARGET']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machinelearning import prediction\n",
    "\n",
    "\n",
    "file=open(\"machinelearning.py\",\"r\",encoding=\"utf-8\")\n",
    "#print(file.read())\n",
    "file.close()\n",
    "del file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# harmonise les types\n",
    "df = df.applymap(float)\n",
    "df['TARGET'] = df['TARGET'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(df,models=[{\"modèle\":LinearSVC,\"paramètres\":{\"random_state\":44}},\n",
    "                       {\"modèle\":RandomForestClassifier,\"paramètres\":{\"n_estimators\":750,\"random_state\":44}},\n",
    "                       {\"modèle\":GradientBoostingClassifier,\"paramètres\":{\"random_state\":44}},\n",
    "                       {\"modèle\":LogisticRegression,\"paramètres\":{\"random_state\":44}},\n",
    "                      {\"modèle\":XGBClassifier,\"paramètres\":{}}\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fichiers=os.listdir(\"./../\")\n",
    "fichiers=list(filter(lambda x : x[-5:]=='.html',fichiers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "for fichier in fichiers:\n",
    "    print(fichier[:-5],':')\n",
    "    f=open(\"./../\"+fichier,'r')\n",
    "    g=f.read()\n",
    "    f.close()\n",
    "    \n",
    "    display(HTML(g))\n",
    "    f=open(\"./../\"+fichier[:-4]+'txt','r')\n",
    "    g=f.read()\n",
    "    f.close()\n",
    "    print(g,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention ne pas lancer si mlflow ne vous intéresse pas\n",
    "os.chdir(\"./../\")\n",
    "import webbrowser\n",
    "webbrowser.open('http://127.0.0.1:5000/', new=2)\n",
    "os.popen('mlflow ui').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
